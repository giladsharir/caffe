{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create, train and run network databases of ImageNet and Getty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific run definitions - Usually all changes are here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.insert(-1, '/home/titan/Devel/yohai/python/scripts/')\n",
    "\n",
    "# #################################################\n",
    "# ## Folders\n",
    "# #################################################\n",
    "caffeRoot = '/home/titan/Devel/caffe_new/caffe/' # root folder of caffe build\n",
    "gettyCategoriesMainRoot = '/home/titan/Devel/Gilad/caffe_lsda/caffe_run_lsda' # root of all per run data\n",
    "databasesFolder = '/home/titan/remote_pc2' # location of the levelDB files (will be created if not there and reused otherwise)\n",
    "\n",
    "# #################################################\n",
    "# ## INPUTS TO THE CAFFE RUNNIGN SCRIPT\n",
    "# #################################################\n",
    "# initialization variables\n",
    "initTrainFrom = 'weights' # Select: snapshot / weights / none\n",
    "#startFromSapshotIter = 15000 # used only if initTrainFrom == snapshot\n",
    "\n",
    "#weightsFileName = os.path.join(caffeRoot, 'models/VGG_ILSVRC_19_layers/VGG_ILSVRC_19_layers.caffemodel') # used only if initTrainFrom ==weights\n",
    "weightsFileName = os.path.join(caffeRoot, 'examples/demo_detection/caffe_annotations_finetune_iter_8000.caffemodel') # used only if initTrainFrom ==weights\n",
    "# mean image \n",
    "meanImageFilename = os.path.join(caffeRoot, \"examples/demo_detection/imagenet_annot_mean.binaryproto\")\n",
    "\n",
    "# snapshot used to run the test on\n",
    "validateAtSnapshot = 75000\n",
    "\n",
    "# YAML files containing a lsit of categories and their relevant sources for images\n",
    "categoriesFile = os.path.join(gettyCategoriesMainRoot, 'categories_gt200annotations.yml')\n",
    "\n",
    "collectionsToUse = ['imagenet'] # set of images to use. Currently: 'imagenet' a/o 'getty' order is irrelevant\n",
    "cropsTypesToUse=None # order mean the precedence\n",
    "testPrecedOrder= None # crop types that have precedence to be in the test set. order is irrelevant\n",
    "isSquareCrops=True # if false will use rectangular crops and therefore will stratch images\n",
    "isIncludeOriginals=True # should add the original image in case there is no crop for the image\n",
    "\n",
    "isIncludeBackground=False\n",
    "isOrigsWithXmlOnly = True\n",
    "xmlAnnotationFolders = ['annotations/xml']\n",
    "\n",
    "\n",
    "# #################################################\n",
    "# ## OUTPUTS OF THE CAFFE RUNNIGN SCRIPT\n",
    "# #################################################\n",
    "#The location of the train/validation files lists.\n",
    "fileListsFolder = gettyCategoriesMainRoot\n",
    "\n",
    "# location of the solver / net files\n",
    "modelFilesFolder = gettyCategoriesMainRoot\n",
    "solverFilename = 'solver.prototxt'\n",
    "netFilename = 'train_val.prototxt'\n",
    "\n",
    "# prefix of images lists files \n",
    "outputFilesPrefix = 'imagenet_lsda_439_annots_orig'\n",
    "\n",
    "snapshotPrefixFullpath = os.path.join(databasesFolder, outputFilesPrefix)\n",
    "\n",
    "# #################################################\n",
    "# ## parameters that are less likely to be changed:\n",
    "# #################################################\n",
    "# root folder of blacklists (list of images that are excluded form train/test)\n",
    "allDataRoot = '/home/titan/remote_pc' \n",
    "solverTemplate = os.path.join(gettyCategoriesMainRoot, '..', 'prototxt_templates/caffenet_solver.prototxt_template')\n",
    "trainValTemplate = os.path.join(gettyCategoriesMainRoot, '..', 'prototxt_templates/caffenet_train_val.prototxt_template')\n",
    "\n",
    "# size of images in databases (0 for no resizing)\n",
    "resizeSize = 256\n",
    "\n",
    "# caffe running setting\n",
    "toolsFolder     = os.path.join(caffeRoot, 'build/tools')  #The location of the precompiled tools \n",
    "\n",
    "caffeTrainExe = 'caffe'\n",
    "caffeTestExe = 'caffe_test_confusion' # in case there is a differnet executable for the testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validate the YAML file and get number of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories file is ok\n"
     ]
    }
   ],
   "source": [
    "import categoryData\n",
    "categoryData.ValidateCategoriesYamlFile(categoriesFile)\n",
    "\n",
    "# from categoryData import CategoryData\n",
    "import yaml            \n",
    "with open(categoriesFile) as stream:\n",
    "    nCategories = len(yaml.load(stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='/tmp/yohai/fileList.log',level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files are up to date. Touch any input file to force recreation.\n",
      "Crop files were not tested for changes.\n"
     ]
    }
   ],
   "source": [
    "## Create images file lists (if needed)\n",
    "#from createCaffeFileLists import CreateCaffeFileLists\n",
    "import createCaffeFileLists\n",
    "reload(createCaffeFileLists)\n",
    "\n",
    "fileNamesAndSizes = createCaffeFileLists.CreateCaffeFileLists(outputFolder=fileListsFolder, outputFilesPrefix=outputFilesPrefix, \n",
    "                                         categoriesFile=categoriesFile,allDataRoot=allDataRoot, \n",
    "                                         collections=collectionsToUse, cropsTypesToUse=cropsTypesToUse,\n",
    "                                         testPrecedOrder=testPrecedOrder, isSquareCrops=isSquareCrops, \n",
    "                                         isIncludeOriginals=isIncludeOriginals,\n",
    "                                         isIncludeBackground=isIncludeBackground,\n",
    "                                         isOrigsWithXmlOnly = isOrigsWithXmlOnly,\n",
    "                                         xmlAnnotationFolders=xmlAnnotationFolders)\n",
    "\n",
    "testListFilename = fileNamesAndSizes['testFilename']\n",
    "trainListFilename = fileNamesAndSizes['trainFilename']\n",
    "testDatabaseFilename = os.path.join(databasesFolder, \"{}_test_{}x{}_leveldb\".format(outputFilesPrefix, resizeSize, resizeSize))\n",
    "trainDatabaseFilename = os.path.join(databasesFolder, \"{}_train_{}x{}_leveldb\".format(outputFilesPrefix, resizeSize, resizeSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# verify that there is enough space on the HD\n",
    "from generalUtils import GetAvailableSpaceInDiskInMB\n",
    "totalImages = fileNamesAndSizes['nTrainFiles'] + fileNamesAndSizes['nTestFiles']\n",
    "requiredDatabaseSpaceMB = float(totalImages) * 0.16 # in iter_04 it took 116GB for ~800K images\n",
    "requiredDatabaseSpaceMB += 10000 # 100000 iterations of caffenet takes 10GB\n",
    "requiredDatabaseSpaceMB *= 1.1 # to be on hte safe side...\n",
    "if GetAvailableSpaceInDiskInMB(databasesFolder) < requiredDatabaseSpaceMB:\n",
    "    raise Exception('It seems that there is not enough space in {}'.format(databasesFolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/titan/remote_pc2/imagenet_lsda_439_annots_orig_test_256x256_leveldb']\n",
      "Creating database /home/titan/remote_pc2/imagenet_lsda_439_annots_orig_test_256x256_leveldb based on file list /home/titan/Devel/Gilad/caffe_lsda/caffe_run_lsda/imagenet_lsda_439_annots_orig_test.txt\n",
      "shell command is:\n",
      "/home/titan/Devel/caffe_new/caffe/build/tools/convert_imageset --shuffle --resize_height=256 --resize_width=256 --backend=leveldb / /home/titan/Devel/Gilad/caffe_lsda/caffe_run_lsda/imagenet_lsda_439_annots_orig_test.txt /home/titan/remote_pc2/imagenet_lsda_439_annots_orig_test_256x256_leveldb\n",
      "\n",
      "\n",
      "['/home/titan/remote_pc2/imagenet_lsda_439_annots_orig_train_256x256_leveldb']\n",
      "Creating database /home/titan/remote_pc2/imagenet_lsda_439_annots_orig_train_256x256_leveldb based on file list /home/titan/Devel/Gilad/caffe_lsda/caffe_run_lsda/imagenet_lsda_439_annots_orig_train.txt\n",
      "shell command is:\n",
      "/home/titan/Devel/caffe_new/caffe/build/tools/convert_imageset --shuffle --resize_height=256 --resize_width=256 --backend=leveldb / /home/titan/Devel/Gilad/caffe_lsda/caffe_run_lsda/imagenet_lsda_439_annots_orig_train.txt /home/titan/remote_pc2/imagenet_lsda_439_annots_orig_train_256x256_leveldb\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Create database files (if needed)\n",
    "from createCaffeFileLists import CreateImagesDatabase\n",
    "\n",
    "CreateImagesDatabase(testListFilename, testDatabaseFilename, databasesFolder, fileListsFolder, toolsFolder, resizeSize)\n",
    "CreateImagesDatabase(trainListFilename, trainDatabaseFilename, databasesFolder, fileListsFolder, toolsFolder, resizeSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create prototxt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from generalUtils import ReplaceMarkersInFile\n",
    "\n",
    "solverFullPath = os.path.join(modelFilesFolder, solverFilename)\n",
    "netFullPath    = os.path.join(modelFilesFolder, netFilename)\n",
    "\n",
    "# print 'Using solver file: ' + solverFullPath\n",
    "# print 'Using net file: ' + netFullPath\n",
    "\n",
    "solverMarkersDict = {'netFileName': netFullPath, 'snapshotsPrefix': snapshotPrefixFullpath}\n",
    "trainValMarkersDict = {'trainDatabaseFilename': trainDatabaseFilename, \n",
    "                      'testDatabaseFilename': testDatabaseFilename, \n",
    "                      'meanFileName': meanImageFilename, \n",
    "                      'numCategories': str(nCategories) }\n",
    "\n",
    "ReplaceMarkersInFile(solverTemplate, solverFullPath, solverMarkersDict)\n",
    "ReplaceMarkersInFile(trainValTemplate, netFullPath, trainValMarkersDict)\n",
    "\n",
    "\n",
    "if False == os.path.isfile(solverFullPath):\n",
    "    raise Exception(\"Solver file doesn't exist:\" + solverFullPath) \n",
    "if False == os.path.isfile(netFullPath):\n",
    "    raise Exception(\"Net file doesn't exist:\" + netFullPath) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from generalUtils import findStringByTag\n",
    "\n",
    "# find the images mean in net file, and verify that there is a single mean for \n",
    "# both test and train phases\n",
    "meanFiles   = findStringByTag(netFullPath, 'mean_file')\n",
    "meanFiles = list(set(meanFiles)) # remove duplicates\n",
    "if len(meanFiles) > 1:\n",
    "    raise Exception(\"There are more than one mean image file:\" + ', '.join(meanFiles))\n",
    "for meanImageName in meanFiles:\n",
    "    if not (os.path.isfile(meanImageName) or os.path.isdir(meanImageName)):\n",
    "        raise Exception(\"Mean image file mentioned is {}.\\n It doesn't exist. \".format(meanImageName) + \n",
    "                        \"You may need to download it using scripts/download_model_binary.py\")\n",
    "\n",
    "# Verify that the last ouput layer has nCategories outputs\n",
    "nLastLayerOutputs = findStringByTag(netFullPath, 'num_output')\n",
    "nLastLayerOutputs = int(nLastLayerOutputs[-1])\n",
    "if nLastLayerOutputs != nCategories:\n",
    "    raise Exception('Final layer has {} outputs whereas there are {} categories'\n",
    "                    .format(nLastLayerOutputs, nCategories))\n",
    "\n",
    "# find snapshot prefix and create its folders\n",
    "snapshotPrefix = findStringByTag(solverFullPath, 'snapshot_prefix')\n",
    "snapshotPrefix = snapshotPrefix[0]\n",
    "if not os.path.isdir(os.path.dirname(snapshotPrefix)):\n",
    "    os.makedirs(os.path.dirname(snapshotPrefix))\n",
    "    \n",
    "# find sources files (images lists for train and test) and verify their existance\n",
    "sourceFiles = findStringByTag(netFullPath, 'source')\n",
    "sourceFiles = list(set(sourceFiles))\n",
    "for src in sourceFiles:\n",
    "    assert(os.path.isfile(src) or os.path.isdir(src))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that the sources in the net file match the prepared sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test batch size is 100\n",
      "All source files in net file are pointing correctly\n"
     ]
    }
   ],
   "source": [
    "# there is a faster way to find the layers but it took me too long to find an appropriate regex\n",
    "import re\n",
    "with open (netFullPath, \"r\") as myfile:   \n",
    "    data=myfile.readlines()\n",
    "\n",
    "layerBegins = [i for (i,l) in enumerate(data) if l.strip() == 'layers {']\n",
    "layerEnds   = [i for (i,l) in enumerate(data) if l.rstrip() == '}']\n",
    "\n",
    "atTrainLayer = [i for (i,l) in enumerate(data) if (len( re.findall(r'phase: TRAIN',l)) > 0)][0]\n",
    "atTestLayer  = [i for (i,l) in enumerate(data) if (len( re.findall(r'phase: TEST',l)) > 0)][0]\n",
    "\n",
    "testBegin = [b for b in layerBegins if b < atTestLayer][-1]\n",
    "testEnd   = [b for b in layerEnds if b > atTestLayer][0]\n",
    "trainBegin = [b for b in layerBegins if b < atTrainLayer][-1]\n",
    "trainEnd   = [b for b in layerEnds if b > atTrainLayer][0]\n",
    "\n",
    "\n",
    "for line in data[testBegin:testEnd]:\n",
    "    line = line.rstrip()  # remove '\\n' at end of line\n",
    "    if -1 != line.find('batch_size:'):\n",
    "        m = re.search('\\:[ \\t]*([a-zA-Z0-9]*)', line)\n",
    "        assert(m)\n",
    "        testBatchSize = int(m.groups()[0])\n",
    "        break\n",
    "print \"Test batch size is \" + str(testBatchSize)\n",
    "\n",
    "sourceFiles = [trainDatabaseFilename, testDatabaseFilename]\n",
    "layerDatas = [ data[trainBegin:trainEnd], data[testBegin:testEnd] ]\n",
    "anyError = False\n",
    "for i in range(2):\n",
    "    for line in layerDatas[i]:\n",
    "        line = line.rstrip()  # remove '\\n' at end of line\n",
    "        if -1 != line.find('source:'):\n",
    "            m = re.search('\"([^\\\"]+)\"', line)\n",
    "            assert(m)\n",
    "            if m.groups()[0] != sourceFiles[i]:\n",
    "                raise Exception('net file is pointing to {} database where the created one is {}'\n",
    "                                .format(m.groups()[0],sourceFiles[i]))\n",
    "if anyError == False:\n",
    "    print \"All source files in net file are pointing correctly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell command is:\n",
      "/home/titan/Devel/caffe_new/caffe/build/tools/caffe train --solver=/home/titan/Devel/Gilad/caffe_lsda/caffe_run_lsda/solver.prototxt --weights=/home/titan/Devel/caffe_new/caffe/examples/demo_detection/caffe_annotations_finetune_iter_8000.caffemodel\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose initialization method\n",
    "\n",
    "shellCommand = os.path.join(toolsFolder, caffeTrainExe)\n",
    "shellOptions = ['train', '--solver='+solverFullPath]\n",
    "if initTrainFrom == 'snapshot':\n",
    "    shellOptions.append('--snapshot='+snapshotPrefix+'_iter_'+str(startFromSapshotIter)+'.solverstate')\n",
    "elif initTrainFrom == 'weights':    \n",
    "    shellOptions.append('--weights='+weightsFileName)\n",
    "else:\n",
    "    assert (initTrainFrom == 'none')\n",
    "\n",
    "print \"shell command is:\\n\"+shellCommand+' '+' '.join(shellOptions)+\"\\n\\n\"\n",
    "# logs are at /tmp/caffe.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from generalUtils import RunShellCommand\n",
    "p = os.getcwd()\n",
    "os.chdir(modelFilesFolder)\n",
    "rc, output = RunShellCommand(shellCommand, shellOptions)\n",
    "if rc != 0:\n",
    "    print output\n",
    "os.chdir(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run the validation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/titan/Devel/caffe_test/caffe_eli/build/tools/caffe_test_confusion ['test', '--model=/home/titan/Devel/GettyCategories/iter_04/train_val.prototxt', '--weights=/Data/GettyCategories/solverStates/iter_04/caffe_getty_iter_04_501Catgories_iter_75000.caffemodel', '--iterations=410', '--terms=/home/titan/Devel/GettyCategories/iter_04/imagenet_getty_501_categories_categoryToLabel.txt', '--gpu=0']\n"
     ]
    }
   ],
   "source": [
    "# caffe executable ma ybe different for test (e.g. we want to use a differnt branch that calculate confusion matrix)\n",
    "# number of iterations should be such that #iterations * btestBatchSize = # of test images\n",
    "\n",
    "shellCommand = os.path.join(toolsFolder, caffeTestExe)\n",
    "shellOptions = ['test', \n",
    "                '--model='+netFullPath,\n",
    "                '--weights=' + snapshotPrefix + '_iter_{}.caffemodel'.format(validateAtSnapshot), \n",
    "                '--iterations=' + str(int(fileNamesAndSizes['nTestFiles'] / testBatchSize)),\n",
    "                '--terms=' + fileNamesAndSizes['termsFilename'],\n",
    "                '--gpu=0'            ]\n",
    "print \"shell command is:\\n\"+shellCommand+' '+' '.join(shellOptions)+\"\\n\\n\"\n",
    "# logs are at /tmp/caffe.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(modelRoot)\n",
    "RunShellCommand(shellCommand, shellOptions)\n",
    "os.chdir(caffeRoot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
